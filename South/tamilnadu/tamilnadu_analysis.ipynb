{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tamil Nadu State Analysis - Digital Equity Index (DEI)\n",
        "\n",
        "This notebook performs analysis of Aadhaar enrollment and update data for Tamil Nadu's **38 official districts**.\n",
        "\n",
        "## Official Tamil Nadu Districts (38)\n",
        "Ariyalur, Chengalpattu, Chennai, Coimbatore, Cuddalore, Dharmapuri, Dindigul, Erode, Kallakurichi, Kanchipuram, Kanyakumari, Karur, Krishnagiri, Madurai, Mayiladuthurai, Nagapattinam, Namakkal, Nilgiris, Perambalur, Pudukkottai, Ramanathapuram, Ranipet, Salem, Sivagangai, Tenkasi, Thanjavur, Theni, Thoothukudi, Tiruchirappalli, Tirunelveli, Tirupattur, Tiruppur, Tiruvallur, Tiruvannamalai, Tiruvarur, Vellore, Viluppuram, Virudhunagar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = r'c:\\Users\\Admin\\OneDrive\\Documents\\AADHAR Hackathon\\tamilnadu'\n",
        "# Note: Files are in root of tamilnadu folder based on scan\n",
        "\n",
        "enrol_df = pd.read_csv(os.path.join(BASE_PATH, 'tamilnadu_enrollment.csv'))\n",
        "demo_df = pd.read_csv(os.path.join(BASE_PATH, 'tamilnadu_demographic.csv'))\n",
        "bio_df = pd.read_csv(os.path.join(BASE_PATH, 'tamilnadu_biometric.csv'))\n",
        "\n",
        "print(f'Enrollment: {len(enrol_df):,} | Demographic: {len(demo_df):,} | Biometric: {len(bio_df):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Raw district names sample:', sorted(enrol_df['district'].unique())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Cleaning - Comprehensive Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Official 38 Tamil Nadu Districts (lowercase)\n",
        "OFFICIAL_DISTRICTS = {\n",
        "    'ariyalur', 'chengalpattu', 'chennai', 'coimbatore', 'cuddalore',\n",
        "    'dharmapuri', 'dindigul', 'erode', 'kallakurichi', 'kanchipuram',\n",
        "    'kanyakumari', 'karur', 'krishnagiri', 'madurai', 'mayiladuthurai',\n",
        "    'nagapattinam', 'namakkal', 'nilgiris', 'perambalur', 'pudukkottai',\n",
        "    'ramanathapuram', 'ranipet', 'salem', 'sivagangai', 'tenkasi',\n",
        "    'thanjavur', 'theni', 'thoothukudi', 'tiruchirappalli', 'tirunelveli',\n",
        "    'tirupattur', 'tiruppur', 'tiruvallur', 'tiruvannamalai', 'tiruvarur',\n",
        "    'vellore', 'viluppuram', 'virudhunagar'\n",
        "}\n",
        "\n",
        "# Comprehensive Mapping: known variants -> official 38 district names\n",
        "DISTRICT_CLEANUP_MAP = {\n",
        "    # Found in Raw Data Scan\n",
        "    'kancheepuram': 'kanchipuram',\n",
        "    'kanniyakumari': 'kanyakumari',\n",
        "    'sivaganga': 'sivagangai',\n",
        "    'the nilgiris': 'nilgiris',\n",
        "    'thiruvallur': 'tiruvallur',\n",
        "    'thiruvarur': 'tiruvarur',\n",
        "    'thoothukkudi': 'thoothukudi',\n",
        "    'tuticorin': 'thoothukudi',\n",
        "    'tirupathur': 'tirupattur',\n",
        "    'villupuram': 'viluppuram',\n",
        "    \n",
        "    # Potential backups\n",
        "    'tiruneveli': 'tirunelveli',\n",
        "    'thiruvannamalai': 'tiruvannamalai',\n",
        "    'virudhunagar *': 'virudhunagar' # Asterisk handling is mostly done by function\n",
        "}\n",
        "\n",
        "def clean_district_name(name):\n",
        "    \"\"\"Normalize district name. Handles typos, whitespace, asterisks.\"\"\"\n",
        "    if pd.isna(name):\n",
        "        return None\n",
        "    \n",
        "    # Lowercase and strip\n",
        "    cleaned = str(name).strip().lower()\n",
        "    \n",
        "    # Remove asterisk suffix\n",
        "    if cleaned.endswith(' *'):\n",
        "        cleaned = cleaned[:-2].strip()\n",
        "    if cleaned.endswith('*'):\n",
        "        cleaned = cleaned[:-1].strip()\n",
        "    \n",
        "    # Apply mapping\n",
        "    if cleaned in DISTRICT_CLEANUP_MAP:\n",
        "        cleaned = DISTRICT_CLEANUP_MAP[cleaned]\n",
        "        \n",
        "    return cleaned\n",
        "\n",
        "print(f'Official districts: {len(OFFICIAL_DISTRICTS)}')\n",
        "print(f'Cleanup mappings: {len(DISTRICT_CLEANUP_MAP)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply cleaning and VALIDATE (Zero Drop Policy)\n",
        "for df in [enrol_df, demo_df, bio_df]:\n",
        "    # 1. Clean\n",
        "    df['district_clean'] = df['district'].apply(clean_district_name)\n",
        "    \n",
        "    # 2. Check for unknowns\n",
        "    unknowns = df[~df['district_clean'].isin(OFFICIAL_DISTRICTS)]['district'].unique()\n",
        "    if len(unknowns) > 0:\n",
        "        print(f'⚠️ CRITICAL: The following districts are still NOT mapped to the official list:\\n{unknowns}')\n",
        "        print('Please update DISTRICT_CLEANUP_MAP.')\n",
        "        \n",
        "    # 3. Apply\n",
        "    df.dropna(subset=['district_clean'], inplace=True)\n",
        "    df['district'] = df['district_clean']\n",
        "    df.drop(columns=['district_clean'], inplace=True)\n",
        "\n",
        "    # 4. Dates\n",
        "    df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
        "    df['month'] = df['date'].dt.month\n",
        "\n",
        "# Verify\n",
        "all_cleaned = set(enrol_df['district'].unique()) | set(demo_df['district'].unique()) | set(bio_df['district'].unique())\n",
        "\n",
        "print(f'\\nFinal Districts ({len(all_cleaned)}):')\n",
        "print(sorted(all_cleaned))\n",
        "\n",
        "if len(all_cleaned) != 38:\n",
        "    print(f'⚠️ Warning: Found {len(all_cleaned)} districts, expected 38. Check if some official districts are absent in data.')\n",
        "else:\n",
        "    print('✅ Exactly 38 districts found! No data lost from known districts.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Aggregation & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate\n",
        "enrol_agg = enrol_df.groupby(['state', 'district', 'month'])[['age_0_5', 'age_5_17', 'age_18_greater']].sum().reset_index()\n",
        "demo_agg = demo_df.groupby(['state', 'district', 'month'])[['demo_age_5_17', 'demo_age_17_']].sum().reset_index()\n",
        "bio_agg = bio_df.groupby(['state', 'district', 'month'])[['bio_age_5_17', 'bio_age_17_']].sum().reset_index()\n",
        "\n",
        "combined_df = enrol_agg.merge(demo_agg, on=['state', 'district', 'month'], how='outer') \\\n",
        "                       .merge(bio_agg, on=['state', 'district', 'month'], how='outer')\n",
        "combined_df.fillna(0, inplace=True)\n",
        "\n",
        "# Core metrics\n",
        "combined_df['E'] = combined_df['age_0_5'] + combined_df['age_5_17'] + combined_df['age_18_greater']\n",
        "combined_df['DU'] = combined_df['demo_age_5_17'] + combined_df['demo_age_17_']\n",
        "combined_df['BU'] = combined_df['bio_age_5_17'] + combined_df['bio_age_17_']\n",
        "combined_df['U'] = combined_df['DU'] + combined_df['BU']\n",
        "combined_df['T'] = combined_df['E'] + combined_df['U']\n",
        "\n",
        "print(f'Combined records: {len(combined_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# District-level aggregation\n",
        "district_df = combined_df.groupby(['state', 'district']).agg(\n",
        "    total_months=('month', 'count'),\n",
        "    active_months=('T', lambda x: (x > 0).sum()),\n",
        "    total_E=('E', 'sum'), total_DU=('DU', 'sum'), total_BU=('BU', 'sum'),\n",
        "    total_U=('U', 'sum'), total_T=('T', 'sum'),\n",
        "    avg_monthly_enrolment=('E', 'mean'),\n",
        "    monthly_volatility=('T', lambda x: x.std(ddof=0) / x.mean() if x.mean() > 0 else 0),\n",
        "    peak_load_ratio=('T', lambda x: x.max() / x.mean() if x.mean() > 0 else 0),\n",
        "    sum_age_0_5=('age_0_5', 'sum'), sum_age_5_17=('age_5_17', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "district_df['zero_months'] = district_df['total_months'] - district_df['active_months']\n",
        "district_df['activity_ratio'] = district_df['active_months'] / district_df['total_months']\n",
        "district_df['zero_month_ratio'] = district_df['zero_months'] / district_df['total_months']\n",
        "district_df['biometric_burden'] = (district_df['total_BU'] / (district_df['total_BU'] + district_df['total_DU'])).fillna(0)\n",
        "district_df['update_dominant'] = np.where(district_df['total_U'] > district_df['total_E'], 1, 0)\n",
        "district_df['enrollment_update_balance'] = (district_df['total_E'] / (district_df['total_E'] + district_df['total_U'])).fillna(0)\n",
        "\n",
        "print(f'Districts computed: {len(district_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DEI Score Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "    min_val, max_val = x.min(), x.max()\n",
        "    if max_val == min_val:\n",
        "        return pd.Series([0.5] * len(x), index=x.index)\n",
        "    return (x - min_val) / (max_val - min_val)\n",
        "\n",
        "def inverse_normalize(x):\n",
        "    return 1 - normalize(x)\n",
        "\n",
        "scores_df = district_df.copy()\n",
        "\n",
        "# DEI Components\n",
        "scores_df['access'] = (scores_df['activity_ratio'] + normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['responsiveness'] = normalize(scores_df['total_U'] / scores_df['total_T'])\n",
        "scores_df['inclusion'] = normalize((scores_df['sum_age_0_5'] + scores_df['sum_age_5_17']) / scores_df['total_E'])\n",
        "scores_df['stability'] = (inverse_normalize(scores_df['monthly_volatility']) + inverse_normalize(scores_df['peak_load_ratio'])) / 2\n",
        "scores_df['visibility'] = scores_df['activity_ratio']\n",
        "\n",
        "# Final scores\n",
        "scores_df['DEI'] = (scores_df['access'] + scores_df['responsiveness'] + scores_df['inclusion'] + scores_df['stability'] + scores_df['visibility']) / 5\n",
        "scores_df['ASS'] = (inverse_normalize(scores_df['activity_ratio']) + inverse_normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['UBS'] = (normalize(scores_df['biometric_burden']) + normalize(scores_df['update_dominant'])) / 2\n",
        "scores_df['SRS'] = (normalize(scores_df['monthly_volatility']) + normalize(scores_df['zero_month_ratio'])) / 2\n",
        "\n",
        "print('DEI calculated!')\n",
        "scores_df[['district', 'DEI', 'ASS', 'UBS', 'SRS']].sort_values('DEI', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary & Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'=== Tamil Nadu Summary ===')\n",
        "print(f'Districts: {len(scores_df)}')\n",
        "print(f'Avg DEI: {scores_df[\"DEI\"].mean():.4f}')\n",
        "print(f'Best: {scores_df.loc[scores_df[\"DEI\"].idxmax(), \"district\"]} ({scores_df[\"DEI\"].max():.4f})')\n",
        "print(f'Worst: {scores_df.loc[scores_df[\"DEI\"].idxmin(), \"district\"]} ({scores_df[\"DEI\"].min():.4f})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save outputs\n",
        "scores_df.to_csv(os.path.join(BASE_PATH, 'tamilnadu_district_analysis.csv'), index=False)\n",
        "scores_df[['state', 'district', 'DEI', 'ASS', 'UBS', 'SRS']].to_csv(\n",
        "    os.path.join(BASE_PATH, 'tamilnadu_district_final_scores.csv'), index=False)\n",
        "print('✅ Saved!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}