{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Andhra Pradesh State Analysis - Digital Equity Index (DEI)\n",
        "\n",
        "This notebook performs analysis of Aadhaar enrollment and update data for Andhra Pradesh's **26 official districts**.\n",
        "\n",
        "## Special Handling\n",
        "- **Telangana Separation**: Districts belonging to Telangana (e.g., Hyderabad, Rangareddy) found in this dataset are filtered out and saved to `telangna_dist_in_andhra.csv` for later aggregation.\n",
        "- **Normalization**: Variants like `Cuddapah` are mapped to `y.s.r. kadapa`.\n",
        "- **Zero Drop**: All valid Andhra districts are mapped; none are dropped.\n",
        "\n",
        "## Official Andhra Districts (26)\n",
        "Alluri Sitharama Raju, Anakapalli, Ananthapuramu, Annamayya, Bapatla, Chittoor, Dr. B.R. Ambedkar Konaseema, East Godavari, Eluru, Guntur, Kakinada, Krishna, Kurnool, Nandyal, NTR, Palnadu, Parvathipuram Manyam, Prakasam, Sri Potti Sriramulu Nellore, Sri Sathya Sai, Srikakulam, Tirupati, Visakhapatnam, Vizianagaram, West Godavari, Y.S.R. Kadapa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = r'c:\\Users\\Admin\\OneDrive\\Documents\\AADHAR Hackathon\\andhra'\n",
        "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
        "\n",
        "enrol_df = pd.read_csv(os.path.join(DATA_PATH, 'andhra_enrollment.csv'))\n",
        "demo_df = pd.read_csv(os.path.join(DATA_PATH, 'andhra_demographic.csv'))\n",
        "bio_df = pd.read_csv(os.path.join(DATA_PATH, 'andhra_biometric.csv'))\n",
        "\n",
        "print(f'Enrollment: {len(enrol_df):,} | Demographic: {len(demo_df):,} | Biometric: {len(bio_df):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Cleaning & Separation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Official 26 AP Districts (lowercase)\n",
        "OFFICIAL_ANDHRA_DISTRICTS = {\n",
        "    'alluri sitharama raju', 'anakapalli', 'ananthapuramu', 'annamayya',\n",
        "    'bapatla', 'chittoor', 'dr. b.r. ambedkar konaseema', 'east godavari',\n",
        "    'eluru', 'guntur', 'kakinada', 'krishna', 'kurnool', 'nandyal',\n",
        "    'ntr', 'palnadu', 'parvathipuram manyam', 'prakasam',\n",
        "    'sri potti sriramulu nellore', 'sri sathya sai', 'srikakulam',\n",
        "    'tirupati', 'visakhapatnam', 'vizianagaram', 'west godavari',\n",
        "    'y.s.r. kadapa'\n",
        "}\n",
        "\n",
        "# Known Telangana Districts (lowercase)\n",
        "TELANGANA_DISTRICTS = {\n",
        "    'adilabad', 'hyderabad', 'karimnagar', 'khammam', 'mahabubnagar',\n",
        "    'medak', 'nalgonda', 'nizamabad', 'rangareddy', 'warangal',\n",
        "    'k.v.rangareddy', 'mahabub nagar', 'karim nagar'\n",
        "}\n",
        "\n",
        "# Mapping Logic\n",
        "DISTRICT_CLEANUP_MAP = {\n",
        "    # --- Andhra Normalization ---\n",
        "    'anantapur': 'ananthapuramu',\n",
        "    'ananthapur': 'ananthapuramu',\n",
        "    'cuddapah': 'y.s.r. kadapa',\n",
        "    'y. s. r': 'y.s.r. kadapa',\n",
        "    'dr. b. r. ambedkar konaseema': 'dr. b.r. ambedkar konaseema',\n",
        "    'n. t. r': 'ntr',\n",
        "    'nellore': 'sri potti sriramulu nellore',\n",
        "    'spsr nellore': 'sri potti sriramulu nellore',\n",
        "    'visakhapatanam': 'visakhapatnam',\n",
        "    \n",
        "    # --- Telangana Normalization (for cleaner separation) ---\n",
        "    'k.v. rangareddy': 'rangareddy',\n",
        "    'k.v.rangareddy': 'rangareddy',\n",
        "    'rangareddi': 'rangareddy',\n",
        "    'karim nagar': 'karimnagar',\n",
        "    'mahabub nagar': 'mahabubnagar',\n",
        "    'mahbubnagar': 'mahabubnagar'\n",
        "}\n",
        "\n",
        "def normalize_name(name):\n",
        "    if pd.isna(name): return None\n",
        "    cleaned = str(name).strip().lower()\n",
        "    if cleaned.endswith(' *'): cleaned = cleaned[:-2].strip()\n",
        "    if cleaned.endswith('*'): cleaned = cleaned[:-1].strip()\n",
        "    if cleaned in DISTRICT_CLEANUP_MAP: cleaned = DISTRICT_CLEANUP_MAP[cleaned]\n",
        "    return cleaned\n",
        "\n",
        "telangana_data = []\n",
        "\n",
        "for df_name, df in [('Enrollment', enrol_df), ('Demographic', demo_df), ('Biometric', bio_df)]:\n",
        "    # 1. Normalize\n",
        "    df['district_norm'] = df['district'].apply(normalize_name)\n",
        "    \n",
        "    # 2. Identify Telangana Records\n",
        "    tg_mask = df['district_norm'].isin(TELANGANA_DISTRICTS)\n",
        "    tg_df = df[tg_mask].copy()\n",
        "    tg_df['source_file'] = df_name\n",
        "    telangana_data.append(tg_df)\n",
        "    \n",
        "    # 3. Filter Main DF to Andhra Only\n",
        "    # Keep only legitimate Andhra districts\n",
        "    df['is_andhra'] = df['district_norm'].isin(OFFICIAL_ANDHRA_DISTRICTS)\n",
        "    \n",
        "    # Log Drops (should only be Telangana or Junk)\n",
        "    dropped = df[~df['is_andhra']]['district'].unique()\n",
        "    # We separate TG drops from Unknown drops for clarity\n",
        "    unknown_drops = [d for d in dropped if normalize_name(d) not in TELANGANA_DISTRICTS]\n",
        "    \n",
        "    if len(unknown_drops) > 0:\n",
        "        print(f'{df_name}: ⚠️ Unknown districts dropped: {unknown_drops}')\n",
        "        \n",
        "    # Apply Filter\n",
        "    df.query('is_andhra == True', inplace=True)\n",
        "    df['district'] = df['district_norm']\n",
        "    df.drop(columns=['district_norm', 'is_andhra'], inplace=True)\n",
        "    \n",
        "    # Dates\n",
        "    df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
        "    df['month'] = df['date'].dt.month\n",
        "\n",
        "# Combine and Save Telangana Data\n",
        "if telangana_data:\n",
        "    all_tg = pd.concat(telangana_data)\n",
        "    tg_out_path = os.path.join(BASE_PATH, 'telangna_dist_in_andhra.csv')\n",
        "    all_tg.to_csv(tg_out_path, index=False)\n",
        "    print(f'✅ Extracted {len(all_tg)} Telangana records to: {tg_out_path}')\n",
        "    print(f'Telangana districts found: {sorted(all_tg[\"district\"].unique())}')\n",
        "else:\n",
        "    print('No Telangana data found.')\n",
        "\n",
        "# Verify Andhra Data\n",
        "final_districts = sorted(enrol_df['district'].unique())\n",
        "print(f'\\nFinal Andhra Districts ({len(final_districts)}):')\n",
        "print(final_districts)\n",
        "if len(final_districts) != 26:\n",
        "    print(f'⚠️ Warning: Expected 26, found {len(final_districts)}')\n",
        "else:\n",
        "    print('✅ Exactly 26 Andhra districts retained.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Aggregation & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate\n",
        "enrol_agg = enrol_df.groupby(['state', 'district', 'month'])[['age_0_5', 'age_5_17', 'age_18_greater']].sum().reset_index()\n",
        "demo_agg = demo_df.groupby(['state', 'district', 'month'])[['demo_age_5_17', 'demo_age_17_']].sum().reset_index()\n",
        "bio_agg = bio_df.groupby(['state', 'district', 'month'])[['bio_age_5_17', 'bio_age_17_']].sum().reset_index()\n",
        "\n",
        "combined_df = enrol_agg.merge(demo_agg, on=['state', 'district', 'month'], how='outer') \\\n",
        "                       .merge(bio_agg, on=['state', 'district', 'month'], how='outer')\n",
        "combined_df.fillna(0, inplace=True)\n",
        "\n",
        "# Core metrics\n",
        "combined_df['E'] = combined_df['age_0_5'] + combined_df['age_5_17'] + combined_df['age_18_greater']\n",
        "combined_df['DU'] = combined_df['demo_age_5_17'] + combined_df['demo_age_17_']\n",
        "combined_df['BU'] = combined_df['bio_age_5_17'] + combined_df['bio_age_17_']\n",
        "combined_df['U'] = combined_df['DU'] + combined_df['BU']\n",
        "combined_df['T'] = combined_df['E'] + combined_df['U']\n",
        "\n",
        "print(f'Combined records: {len(combined_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# District-level aggregation\n",
        "district_df = combined_df.groupby(['state', 'district']).agg(\n",
        "    total_months=('month', 'count'),\n",
        "    active_months=('T', lambda x: (x > 0).sum()),\n",
        "    total_E=('E', 'sum'), total_DU=('DU', 'sum'), total_BU=('BU', 'sum'),\n",
        "    total_U=('U', 'sum'), total_T=('T', 'sum'),\n",
        "    avg_monthly_enrolment=('E', 'mean'),\n",
        "    monthly_volatility=('T', lambda x: x.std(ddof=0) / x.mean() if x.mean() > 0 else 0),\n",
        "    peak_load_ratio=('T', lambda x: x.max() / x.mean() if x.mean() > 0 else 0),\n",
        "    sum_age_0_5=('age_0_5', 'sum'), sum_age_5_17=('age_5_17', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "district_df['zero_months'] = district_df['total_months'] - district_df['active_months']\n",
        "district_df['activity_ratio'] = district_df['active_months'] / district_df['total_months']\n",
        "district_df['zero_month_ratio'] = district_df['zero_months'] / district_df['total_months']\n",
        "district_df['biometric_burden'] = (district_df['total_BU'] / (district_df['total_BU'] + district_df['total_DU'])).fillna(0)\n",
        "district_df['update_dominant'] = np.where(district_df['total_U'] > district_df['total_E'], 1, 0)\n",
        "district_df['enrollment_update_balance'] = (district_df['total_E'] / (district_df['total_E'] + district_df['total_U'])).fillna(0)\n",
        "\n",
        "print(f'Districts computed: {len(district_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DEI Score Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "    min_val, max_val = x.min(), x.max()\n",
        "    if max_val == min_val:\n",
        "        return pd.Series([0.5] * len(x), index=x.index)\n",
        "    return (x - min_val) / (max_val - min_val)\n",
        "\n",
        "def inverse_normalize(x):\n",
        "    return 1 - normalize(x)\n",
        "\n",
        "scores_df = district_df.copy()\n",
        "\n",
        "# DEI Components\n",
        "scores_df['access'] = (scores_df['activity_ratio'] + normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['responsiveness'] = normalize(scores_df['total_U'] / scores_df['total_T'])\n",
        "scores_df['inclusion'] = normalize((scores_df['sum_age_0_5'] + scores_df['sum_age_5_17']) / scores_df['total_E'])\n",
        "scores_df['stability'] = (inverse_normalize(scores_df['monthly_volatility']) + inverse_normalize(scores_df['peak_load_ratio'])) / 2\n",
        "scores_df['visibility'] = scores_df['activity_ratio']\n",
        "\n",
        "# Final scores\n",
        "scores_df['DEI'] = (scores_df['access'] + scores_df['responsiveness'] + scores_df['inclusion'] + scores_df['stability'] + scores_df['visibility']) / 5\n",
        "scores_df['ASS'] = (inverse_normalize(scores_df['activity_ratio']) + inverse_normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['UBS'] = (normalize(scores_df['biometric_burden']) + normalize(scores_df['update_dominant'])) / 2\n",
        "scores_df['SRS'] = (normalize(scores_df['monthly_volatility']) + normalize(scores_df['zero_month_ratio'])) / 2\n",
        "\n",
        "print('DEI calculated!')\n",
        "scores_df[['district', 'DEI', 'ASS', 'UBS', 'SRS']].sort_values('DEI', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save outputs\n",
        "scores_df.to_csv(os.path.join(BASE_PATH, 'andhra_district_analysis.csv'), index=False)\n",
        "scores_df[['state', 'district', 'DEI', 'ASS', 'UBS', 'SRS']].to_csv(\n",
        "    os.path.join(BASE_PATH, 'andhra_district_final_scores.csv'), index=False)\n",
        "print('✅ Saved!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}