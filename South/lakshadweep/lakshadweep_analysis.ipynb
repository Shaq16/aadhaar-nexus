{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lakshadweep Analysis - Digital Equity Index (DEI)\n",
        "\n",
        "This notebook performs analysis of Aadhaar enrollment and update data for **Lakshadweep (UT)**.\n",
        "\n",
        "## Official Districts (1)\n",
        "Lakshadweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\Admin\\\\OneDrive\\\\Documents\\\\AADHAR Hackathon\\\\lakshadweep\\\\lakshwadeep_enrollment.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m DATA_PATH = os.path.join(BASE_PATH, \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Note: Files are in the root directory for Lakshadweep\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m enrol_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlakshwadeep_enrollment.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m demo_df = pd.read_csv(os.path.join(BASE_PATH, \u001b[33m'\u001b[39m\u001b[33mlakshwadeep_demographic.csv\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      8\u001b[39m bio_df = pd.read_csv(os.path.join(BASE_PATH, \u001b[33m'\u001b[39m\u001b[33mlakshwadeep_biometric.csv\u001b[39m\u001b[33m'\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\pipx\\venvs\\poetry\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\pipx\\venvs\\poetry\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\pipx\\venvs\\poetry\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\pipx\\venvs\\poetry\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Admin\\pipx\\venvs\\poetry\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Admin\\\\OneDrive\\\\Documents\\\\AADHAR Hackathon\\\\lakshadweep\\\\lakshwadeep_enrollment.csv'"
          ]
        }
      ],
      "source": [
        "BASE_PATH = r'c:\\Users\\Admin\\OneDrive\\Documents\\AADHAR Hackathon\\lakshadweep'\n",
        "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
        "\n",
        "# Note: Files are in the root directory for Lakshadweep\n",
        "\n",
        "enrol_df = pd.read_csv(os.path.join(BASE_PATH, 'lakshwadeep_enrollment.csv'))\n",
        "demo_df = pd.read_csv(os.path.join(BASE_PATH, 'lakshwadeep_demographic.csv'))\n",
        "bio_df = pd.read_csv(os.path.join(BASE_PATH, 'lakshwadeep_biometric.csv'))\n",
        "\n",
        "print(f'Enrollment: {len(enrol_df):,} | Demographic: {len(demo_df):,} | Biometric: {len(bio_df):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Official districts: 1\n"
          ]
        }
      ],
      "source": [
        "# Official 1 District\n",
        "OFFICIAL_DISTRICTS = {'lakshadweep'}\n",
        "\n",
        "DISTRICT_CLEANUP_MAP = {}\n",
        "\n",
        "def clean_district_name(name):\n",
        "    if pd.isna(name):\n",
        "        return None\n",
        "    \n",
        "    # Lowercase and strip\n",
        "    cleaned = str(name).strip().lower()\n",
        "    \n",
        "    # Remove asterisk\n",
        "    if cleaned.endswith(' *'):\n",
        "        cleaned = cleaned[:-2].strip()\n",
        "    if cleaned.endswith('*'):\n",
        "        cleaned = cleaned[:-1].strip()\n",
        "    \n",
        "    # Apply mapping\n",
        "    if cleaned in DISTRICT_CLEANUP_MAP:\n",
        "        cleaned = DISTRICT_CLEANUP_MAP[cleaned]\n",
        "        \n",
        "    return cleaned\n",
        "\n",
        "print(f'Official districts: {len(OFFICIAL_DISTRICTS)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Districts (1):\n",
            "['lakshadweep']\n",
            "✅ Exactly 1 district found!\n"
          ]
        }
      ],
      "source": [
        "# Apply cleaning and VALIDATE check\n",
        "for df in [enrol_df, demo_df, bio_df]:\n",
        "    # 1. Clean\n",
        "    df['district_clean'] = df['district'].apply(clean_district_name)\n",
        "    \n",
        "    # 2. Check for unknowns\n",
        "    unknowns = df[~df['district_clean'].isin(OFFICIAL_DISTRICTS)]['district'].unique()\n",
        "    if len(unknowns) > 0:\n",
        "        print(f'⚠️ CRITICAL: The following districts are still NOT mapped to the official list:\\n{unknowns}')\n",
        "            \n",
        "    # 3. Apply\n",
        "    df.dropna(subset=['district_clean'], inplace=True)\n",
        "    df['district'] = df['district_clean']\n",
        "    df.drop(columns=['district_clean'], inplace=True)\n",
        "\n",
        "    # 4. Dates\n",
        "    df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
        "    df['month'] = df['date'].dt.month\n",
        "\n",
        "# Verify\n",
        "all_cleaned = set(enrol_df['district'].unique()) | set(demo_df['district'].unique()) | set(bio_df['district'].unique())\n",
        "print(f'\\nFinal Districts ({len(all_cleaned)}):')\n",
        "print(sorted(all_cleaned))\n",
        "\n",
        "if len(all_cleaned) != 1:\n",
        "    print(f'⚠️ Warning: Expected 1 district, found {len(all_cleaned)}.')\n",
        "else:\n",
        "    print('✅ Exactly 1 district found!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Aggregation & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined records: 11\n"
          ]
        }
      ],
      "source": [
        "# Aggregate\n",
        "enrol_agg = enrol_df.groupby(['state', 'district', 'month'])[['age_0_5', 'age_5_17', 'age_18_greater']].sum().reset_index()\n",
        "demo_agg = demo_df.groupby(['state', 'district', 'month'])[['demo_age_5_17', 'demo_age_17_']].sum().reset_index()\n",
        "bio_agg = bio_df.groupby(['state', 'district', 'month'])[['bio_age_5_17', 'bio_age_17_']].sum().reset_index()\n",
        "\n",
        "combined_df = enrol_agg.merge(demo_agg, on=['state', 'district', 'month'], how='outer') \\\n",
        "                       .merge(bio_agg, on=['state', 'district', 'month'], how='outer')\n",
        "combined_df.fillna(0, inplace=True)\n",
        "\n",
        "# Core metrics\n",
        "combined_df['E'] = combined_df['age_0_5'] + combined_df['age_5_17'] + combined_df['age_18_greater']\n",
        "combined_df['DU'] = combined_df['demo_age_5_17'] + combined_df['demo_age_17_']\n",
        "combined_df['BU'] = combined_df['bio_age_5_17'] + combined_df['bio_age_17_']\n",
        "combined_df['U'] = combined_df['DU'] + combined_df['BU']\n",
        "combined_df['T'] = combined_df['E'] + combined_df['U']\n",
        "\n",
        "print(f'Combined records: {len(combined_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Districts computed: 1\n"
          ]
        }
      ],
      "source": [
        "# District-level aggregation\n",
        "district_df = combined_df.groupby(['state', 'district']).agg(\n",
        "    total_months=('month', 'count'),\n",
        "    active_months=('T', lambda x: (x > 0).sum()),\n",
        "    total_E=('E', 'sum'), total_DU=('DU', 'sum'), total_BU=('BU', 'sum'),\n",
        "    total_U=('U', 'sum'), total_T=('T', 'sum'),\n",
        "    avg_monthly_enrolment=('E', 'mean'),\n",
        "    monthly_volatility=('T', lambda x: x.std(ddof=0) / x.mean() if x.mean() > 0 else 0),\n",
        "    peak_load_ratio=('T', lambda x: x.max() / x.mean() if x.mean() > 0 else 0),\n",
        "    sum_age_0_5=('age_0_5', 'sum'), sum_age_5_17=('age_5_17', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "district_df['zero_months'] = district_df['total_months'] - district_df['active_months']\n",
        "district_df['activity_ratio'] = district_df['active_months'] / district_df['total_months']\n",
        "district_df['zero_month_ratio'] = district_df['zero_months'] / district_df['total_months']\n",
        "district_df['biometric_burden'] = (district_df['total_BU'] / (district_df['total_BU'] + district_df['total_DU'])).fillna(0)\n",
        "district_df['update_dominant'] = np.where(district_df['total_U'] > district_df['total_E'], 1, 0)\n",
        "district_df['enrollment_update_balance'] = (district_df['total_E'] / (district_df['total_E'] + district_df['total_U'])).fillna(0)\n",
        "\n",
        "print(f'Districts computed: {len(district_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DEI Score Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEI calculated!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>district</th>\n",
              "      <th>DEI</th>\n",
              "      <th>ASS</th>\n",
              "      <th>UBS</th>\n",
              "      <th>SRS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lakshadweep</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      district   DEI  ASS  UBS  SRS\n",
              "0  lakshadweep  0.65  0.5  0.5  0.5"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def normalize(x):\n",
        "    min_val, max_val = x.min(), x.max()\n",
        "    if max_val == min_val:\n",
        "        return pd.Series([0.5] * len(x), index=x.index)\n",
        "    return (x - min_val) / (max_val - min_val)\n",
        "\n",
        "def inverse_normalize(x):\n",
        "    return 1 - normalize(x)\n",
        "\n",
        "scores_df = district_df.copy()\n",
        "\n",
        "# DEI Components\n",
        "scores_df['access'] = (scores_df['activity_ratio'] + normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['responsiveness'] = normalize(scores_df['total_U'] / scores_df['total_T'])\n",
        "scores_df['inclusion'] = normalize((scores_df['sum_age_0_5'] + scores_df['sum_age_5_17']) / scores_df['total_E'])\n",
        "scores_df['stability'] = (inverse_normalize(scores_df['monthly_volatility']) + inverse_normalize(scores_df['peak_load_ratio'])) / 2\n",
        "scores_df['visibility'] = scores_df['activity_ratio']\n",
        "\n",
        "# Final scores\n",
        "scores_df['DEI'] = (scores_df['access'] + scores_df['responsiveness'] + scores_df['inclusion'] + scores_df['stability'] + scores_df['visibility']) / 5\n",
        "scores_df['ASS'] = (inverse_normalize(scores_df['activity_ratio']) + inverse_normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['UBS'] = (normalize(scores_df['biometric_burden']) + normalize(scores_df['update_dominant'])) / 2\n",
        "scores_df['SRS'] = (normalize(scores_df['monthly_volatility']) + normalize(scores_df['zero_month_ratio'])) / 2\n",
        "\n",
        "print('DEI calculated!')\n",
        "scores_df[['district', 'DEI', 'ASS', 'UBS', 'SRS']].sort_values('DEI', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Lakshadweep Summary ===\n",
            "Districts: 1\n",
            "Avg DEI: 0.6500\n",
            "Score: lakshadweep (0.6500)\n"
          ]
        }
      ],
      "source": [
        "print(f'=== Lakshadweep Summary ===')\n",
        "print(f'Districts: {len(scores_df)}')\n",
        "print(f'Avg DEI: {scores_df[\"DEI\"].mean():.4f}')\n",
        "print(f'Score: {scores_df.loc[scores_df[\"DEI\"].idxmax(), \"district\"]} ({scores_df[\"DEI\"].max():.4f})')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved!\n"
          ]
        }
      ],
      "source": [
        "# Save outputs\n",
        "scores_df.to_csv(os.path.join(BASE_PATH, 'lakshadweep_district_analysis.csv'), index=False)\n",
        "scores_df[['state', 'district', 'DEI', 'ASS', 'UBS', 'SRS']].to_csv(\n",
        "    os.path.join(BASE_PATH, 'lakshadweep_district_final_scores.csv'), index=False)\n",
        "print('✅ Saved!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
