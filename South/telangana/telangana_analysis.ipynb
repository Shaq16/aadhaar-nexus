{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Telangana State Analysis - Digital Equity Index (DEI)\n",
        "\n",
        "This notebook performs analysis of Aadhaar enrollment and update data for Telangana's **33 official districts**.\n",
        "\n",
        "## Data Sources\n",
        "- **State Data**: `telangana_enrollment.csv`, `telangana_demographic.csv`, `telangana_biometric.csv`\n",
        "- **Extracted Data**: `telangna_dist_in_andhra.csv` (Records found in Andhra dataset)\n",
        "\n",
        "## Official Telangana Districts (33)\n",
        "Adilabad, Bhadradri Kothagudem, Hanumakonda, Hyderabad, Jagtial, Jangaon, Jayashankar Bhupalpally, Jogulamba Gadwal, Kamareddy, Karimnagar, Khammam, Komaram Bheem Asifabad, Mahabubabad, Mahabubnagar, Mancherial, Medak, Medchal–Malkajgiri, Mulugu, Nagarkurnool, Nalgonda, Narayanpet, Nirmal, Nizamabad, Peddapalli, Rajanna Sircilla, Rangareddy, Sangareddy, Siddipet, Suryapet, Vikarabad, Wanaparthy, Warangal, Yadadri Bhuvanagiri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_rows', 200)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_PATH = r'c:\\Users\\Admin\\OneDrive\\Documents\\AADHAR Hackathon\\telangana'\n",
        "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
        "\n",
        "# Main State Files\n",
        "enrol_df = pd.read_csv(os.path.join(DATA_PATH, 'telangana_enrollment.csv'))\n",
        "demo_df = pd.read_csv(os.path.join(DATA_PATH, 'telangana_demographic.csv'))\n",
        "bio_df = pd.read_csv(os.path.join(DATA_PATH, 'telangana_biometric.csv'))\n",
        "\n",
        "# Extracted Data from Andhra\n",
        "tg_extracted_path = os.path.join(DATA_PATH, 'telangna_dist_in_andhra.csv')\n",
        "if os.path.exists(tg_extracted_path):\n",
        "    tg_extracted_df = pd.read_csv(tg_extracted_path)\n",
        "    print(f'Loaded {len(tg_extracted_df)} records from extracted file.')\n",
        "else:\n",
        "    tg_extracted_df = pd.DataFrame()\n",
        "    print('Warning: Extracted Telangana file not found.')\n",
        "\n",
        "print(f'Enrollment: {len(enrol_df):,} | Demographic: {len(demo_df):,} | Biometric: {len(bio_df):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge Extracted Data into respective DataFrames\n",
        "# Note: The extracted file is a concatenation of all 3 types with a 'source_file' column\n",
        "if not tg_extracted_df.empty:\n",
        "    # Split back by source\n",
        "    ext_enrol = tg_extracted_df[tg_extracted_df['source_file'] == 'Enrollment'].drop(columns=['source_file'])\n",
        "    ext_demo = tg_extracted_df[tg_extracted_df['source_file'] == 'Demographic'].drop(columns=['source_file'])\n",
        "    ext_bio = tg_extracted_df[tg_extracted_df['source_file'] == 'Biometric'].drop(columns=['source_file'])\n",
        "    \n",
        "    # Append\n",
        "    enrol_df = pd.concat([enrol_df, ext_enrol], ignore_index=True)\n",
        "    demo_df = pd.concat([demo_df, ext_demo], ignore_index=True)\n",
        "    bio_df = pd.concat([bio_df, ext_bio], ignore_index=True)\n",
        "    \n",
        "    print(f'Merged Counts -> Enrollment: {len(enrol_df):,} | Demographic: {len(demo_df):,} | Biometric: {len(bio_df):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Cleaning - Comprehensive Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Official 33 TG Districts (lowercase)\n",
        "# Note: 'medchal–malkajgiri' uses en-dash\n",
        "OFFICIAL_DISTRICTS = {\n",
        "    'adilabad', 'bhadradri kothagudem', 'hanumakonda', 'hyderabad', 'jagtial',\n",
        "    'jangaon', 'jayashankar bhupalpally', 'jogulamba gadwal', 'kamareddy',\n",
        "    'karimnagar', 'khammam', 'komaram bheem asifabad', 'mahabubabad',\n",
        "    'mahabubnagar', 'mancherial', 'medak', 'medchal–malkajgiri', 'mulugu',\n",
        "    'nagarkurnool', 'nalgonda', 'narayanpet', 'nirmal', 'nizamabad',\n",
        "    'peddapalli', 'rajanna sircilla', 'rangareddy', 'sangareddy', 'siddipet',\n",
        "    'suryapet', 'vikarabad', 'wanaparthy', 'warangal', 'yadadri bhuvanagiri'\n",
        "}\n",
        "\n",
        "DISTRICT_CLEANUP_MAP = {\n",
        "    # --- Warangal Splitting ---\n",
        "    'warangal urban': 'hanumakonda',\n",
        "    'warangal (urban)': 'hanumakonda',\n",
        "    'warangal rural': 'warangal',\n",
        "    'warangal (rural)': 'warangal',\n",
        "    \n",
        "    # --- Short Names / Typos ---\n",
        "    'bhadradri': 'bhadradri kothagudem',\n",
        "    'jayashankar': 'jayashankar bhupalpally',\n",
        "    'jogulamba': 'jogulamba gadwal',\n",
        "    'komaram bheem': 'komaram bheem asifabad',\n",
        "    'komaram bheem asifaba': 'komaram bheem asifabad',\n",
        "    'rajanna': 'rajanna sircilla',\n",
        "    'yadadri': 'yadadri bhuvanagiri',\n",
        "    'yadadri bhuvanagi': 'yadadri bhuvanagiri',\n",
        "    \n",
        "    # --- Formatting / Typo / Encoding Issues ---\n",
        "    'jangaon.': 'jangaon',\n",
        "    'jagitial': 'jagtial',\n",
        "    'jangoan': 'jangaon',\n",
        "    \n",
        "    # Medchal Variants\n",
        "    'medchal-malkajgiri': 'medchal–malkajgiri', \n",
        "    'medchal?malkajgiri': 'medchal–malkajgiri',\n",
        "    'medchalâ\\x88\\x92malkajgiri': 'medchal–malkajgiri',\n",
        "    'medchalâ\\x80\\x93malkajgiri': 'medchal–malkajgiri',\n",
        "    'medchal−malkajgiri': 'medchal–malkajgiri', # U+2212 Minus Sign\n",
        "    'medchal malkajgiri': 'medchal–malkajgiri',\n",
        "\n",
        "    # Rangareddy Variants\n",
        "    'k.v. rangareddy': 'rangareddy',\n",
        "    'k.v.rangareddy': 'rangareddy',\n",
        "    'ranga reddy': 'rangareddy',\n",
        "    'rangareddi': 'rangareddy',\n",
        "    \n",
        "    'mahabub nagar': 'mahabubnagar',\n",
        "    'mahbubnagar': 'mahabubnagar',\n",
        "    'karim nagar': 'karimnagar'\n",
        "}\n",
        "\n",
        "def clean_district_name(name):\n",
        "    if pd.isna(name):\n",
        "        return None\n",
        "    \n",
        "    # Lowercase and strip\n",
        "    cleaned = str(name).strip().lower()\n",
        "    \n",
        "    # Remove asterisk\n",
        "    if cleaned.endswith(' *'):\n",
        "        cleaned = cleaned[:-2].strip()\n",
        "    if cleaned.endswith('*'):\n",
        "        cleaned = cleaned[:-1].strip()\n",
        "        \n",
        "    # Remove trailing dot (common in this dataset)\n",
        "    if cleaned.endswith('.'):\n",
        "        cleaned = cleaned[:-1].strip()\n",
        "    \n",
        "    # Apply mapping\n",
        "    if cleaned in DISTRICT_CLEANUP_MAP:\n",
        "        cleaned = DISTRICT_CLEANUP_MAP[cleaned]\n",
        "        \n",
        "    return cleaned\n",
        "\n",
        "print(f'Official districts: {len(OFFICIAL_DISTRICTS)}')\n",
        "print(f'Cleanup mappings: {len(DISTRICT_CLEANUP_MAP)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply cleaning and VALIDATE check\n",
        "for df in [enrol_df, demo_df, bio_df]:\n",
        "    # 1. Clean\n",
        "    df['district_clean'] = df['district'].apply(clean_district_name)\n",
        "    \n",
        "    # 2. Check for unknowns\n",
        "    # Note: Using replace for hyphen check to handle encoding differences just for validation\n",
        "    unknowns_mask = ~df['district_clean'].isin(OFFICIAL_DISTRICTS)\n",
        "    if unknowns_mask.any():\n",
        "        # Try fuzzy check on dash\n",
        "        unknown_vals = df[unknowns_mask]['district_clean'].unique()\n",
        "        normalized_officials = {d.replace('–', '-') for d in OFFICIAL_DISTRICTS}\n",
        "        really_unknown = []\n",
        "        for u in unknown_vals:\n",
        "             if pd.notna(u) and u.replace('–', '-') not in normalized_officials:\n",
        "                 really_unknown.append(u)\n",
        "        \n",
        "        if really_unknown:\n",
        "            print(f'⚠️ CRITICAL: Unmapped districts found: {really_unknown}')\n",
        "            \n",
        "    # 3. Apply\n",
        "    df.dropna(subset=['district_clean'], inplace=True)\n",
        "    df['district'] = df['district_clean']\n",
        "    df.drop(columns=['district_clean'], inplace=True)\n",
        "\n",
        "    # 4. Dates\n",
        "    df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
        "    df['month'] = df['date'].dt.month\n",
        "\n",
        "# Verify\n",
        "all_cleaned = set(enrol_df['district'].unique()) | set(demo_df['district'].unique()) | set(bio_df['district'].unique())\n",
        "print(f'\\nFinal Districts ({len(all_cleaned)}):')\n",
        "print(sorted(all_cleaned))\n",
        "\n",
        "if len(all_cleaned) != 33:\n",
        "    print(f'⚠️ Warning: Expected 33 districts, found {len(all_cleaned)}.')\n",
        "else:\n",
        "    print('✅ Exactly 33 districts found!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Aggregation & Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate\n",
        "enrol_agg = enrol_df.groupby(['state', 'district', 'month'])[['age_0_5', 'age_5_17', 'age_18_greater']].sum().reset_index()\n",
        "demo_agg = demo_df.groupby(['state', 'district', 'month'])[['demo_age_5_17', 'demo_age_17_']].sum().reset_index()\n",
        "bio_agg = bio_df.groupby(['state', 'district', 'month'])[['bio_age_5_17', 'bio_age_17_']].sum().reset_index()\n",
        "\n",
        "combined_df = enrol_agg.merge(demo_agg, on=['state', 'district', 'month'], how='outer') \\\n",
        "                       .merge(bio_agg, on=['state', 'district', 'month'], how='outer')\n",
        "combined_df.fillna(0, inplace=True)\n",
        "\n",
        "# Core metrics\n",
        "combined_df['E'] = combined_df['age_0_5'] + combined_df['age_5_17'] + combined_df['age_18_greater']\n",
        "combined_df['DU'] = combined_df['demo_age_5_17'] + combined_df['demo_age_17_']\n",
        "combined_df['BU'] = combined_df['bio_age_5_17'] + combined_df['bio_age_17_']\n",
        "combined_df['U'] = combined_df['DU'] + combined_df['BU']\n",
        "combined_df['T'] = combined_df['E'] + combined_df['U']\n",
        "\n",
        "print(f'Combined records: {len(combined_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# District-level aggregation\n",
        "district_df = combined_df.groupby(['state', 'district']).agg(\n",
        "    total_months=('month', 'count'),\n",
        "    active_months=('T', lambda x: (x > 0).sum()),\n",
        "    total_E=('E', 'sum'), total_DU=('DU', 'sum'), total_BU=('BU', 'sum'),\n",
        "    total_U=('U', 'sum'), total_T=('T', 'sum'),\n",
        "    avg_monthly_enrolment=('E', 'mean'),\n",
        "    monthly_volatility=('T', lambda x: x.std(ddof=0) / x.mean() if x.mean() > 0 else 0),\n",
        "    peak_load_ratio=('T', lambda x: x.max() / x.mean() if x.mean() > 0 else 0),\n",
        "    sum_age_0_5=('age_0_5', 'sum'), sum_age_5_17=('age_5_17', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "district_df['zero_months'] = district_df['total_months'] - district_df['active_months']\n",
        "district_df['activity_ratio'] = district_df['active_months'] / district_df['total_months']\n",
        "district_df['zero_month_ratio'] = district_df['zero_months'] / district_df['total_months']\n",
        "district_df['biometric_burden'] = (district_df['total_BU'] / (district_df['total_BU'] + district_df['total_DU'])).fillna(0)\n",
        "district_df['update_dominant'] = np.where(district_df['total_U'] > district_df['total_E'], 1, 0)\n",
        "district_df['enrollment_update_balance'] = (district_df['total_E'] / (district_df['total_E'] + district_df['total_U'])).fillna(0)\n",
        "\n",
        "print(f'Districts computed: {len(district_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DEI Score Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "    min_val, max_val = x.min(), x.max()\n",
        "    if max_val == min_val:\n",
        "        return pd.Series([0.5] * len(x), index=x.index)\n",
        "    return (x - min_val) / (max_val - min_val)\n",
        "\n",
        "def inverse_normalize(x):\n",
        "    return 1 - normalize(x)\n",
        "\n",
        "scores_df = district_df.copy()\n",
        "\n",
        "# DEI Components\n",
        "scores_df['access'] = (scores_df['activity_ratio'] + normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['responsiveness'] = normalize(scores_df['total_U'] / scores_df['total_T'])\n",
        "scores_df['inclusion'] = normalize((scores_df['sum_age_0_5'] + scores_df['sum_age_5_17']) / scores_df['total_E'])\n",
        "scores_df['stability'] = (inverse_normalize(scores_df['monthly_volatility']) + inverse_normalize(scores_df['peak_load_ratio'])) / 2\n",
        "scores_df['visibility'] = scores_df['activity_ratio']\n",
        "\n",
        "# Final scores\n",
        "scores_df['DEI'] = (scores_df['access'] + scores_df['responsiveness'] + scores_df['inclusion'] + scores_df['stability'] + scores_df['visibility']) / 5\n",
        "scores_df['ASS'] = (inverse_normalize(scores_df['activity_ratio']) + inverse_normalize(scores_df['avg_monthly_enrolment'])) / 2\n",
        "scores_df['UBS'] = (normalize(scores_df['biometric_burden']) + normalize(scores_df['update_dominant'])) / 2\n",
        "scores_df['SRS'] = (normalize(scores_df['monthly_volatility']) + normalize(scores_df['zero_month_ratio'])) / 2\n",
        "\n",
        "print('DEI calculated!')\n",
        "scores_df[['district', 'DEI', 'ASS', 'UBS', 'SRS']].sort_values('DEI', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save outputs\n",
        "scores_df.to_csv(os.path.join(BASE_PATH, 'telangana_district_analysis.csv'), index=False)\n",
        "scores_df[['state', 'district', 'DEI', 'ASS', 'UBS', 'SRS']].to_csv(\n",
        "    os.path.join(BASE_PATH, 'telangana_district_final_scores.csv'), index=False)\n",
        "print('✅ Saved!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}